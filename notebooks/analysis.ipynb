{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c9c400a-9776-4ba8-a423-d502c7606197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ OPTIONS DE TRAITEMENT DES OUTLIERS\n",
      "==================================================\n",
      "  winsorize: Winsorization (remplacement par percentiles)\n",
      "  cap: Capping IQR (troncature des extr√™mes)\n",
      "  log: Transformation logarithmique\n",
      "  remove: Suppression des outliers\n",
      "üöÄ D√âMARRAGE DU PIPELINE AVEC TRAITEMENT DES OUTLIERS\n",
      "======================================================================\n",
      "üìå M√©thode de traitement des outliers: winsorize\n",
      "üìå RobustScaler pour ML: True\n",
      "‚úÖ Donn√©es charg√©es : 300 lignes, 8 colonnes\n",
      "\n",
      "üîç ANALYSE INITIALE DES OUTLIERS\n",
      "\n",
      "üìä ANALYSE D√âTAILL√âE DES VALEURS ABERRANTES\n",
      "============================================================\n",
      "\n",
      "üìà speed_kmh:\n",
      "  Moyenne: 28.7867\n",
      "  M√©diane: 28.5000\n",
      "  Std: 7.4039\n",
      "  Min: 10.0000\n",
      "  Max: 48.0000\n",
      "  Q1: 24.0000\n",
      "  Q3: 33.0000\n",
      "  IQR: 9.0000\n",
      "  Skewness: 0.0295\n",
      "  Kurtosis: -0.1488\n",
      "  Outliers (IQR): 4 (1.33%)\n",
      "  Plage normale: [10.5000, 46.5000]\n",
      "  Exemples d'outliers: [47 10 48 47]\n",
      "\n",
      "üìà traffic_density:\n",
      "  Moyenne: 0.3114\n",
      "  M√©diane: 0.2850\n",
      "  Std: 0.1687\n",
      "  Min: 0.0500\n",
      "  Max: 0.8400\n",
      "  Q1: 0.1800\n",
      "  Q3: 0.4300\n",
      "  IQR: 0.2500\n",
      "  Skewness: 0.6195\n",
      "  Kurtosis: -0.0819\n",
      "  Outliers (IQR): 1 (0.33%)\n",
      "  Plage normale: [-0.1950, 0.8050]\n",
      "  Exemples d'outliers: [0.84]\n",
      "\n",
      "üìà air_quality_index:\n",
      "  Moyenne: 63.9100\n",
      "  M√©diane: 63.0000\n",
      "  Std: 12.2076\n",
      "  Min: 33.0000\n",
      "  Max: 97.0000\n",
      "  Q1: 55.0000\n",
      "  Q3: 72.2500\n",
      "  IQR: 17.2500\n",
      "  Skewness: 0.2704\n",
      "  Kurtosis: -0.3745\n",
      "  Outliers (IQR): 0 (0.00%)\n",
      "  Plage normale: [29.1250, 98.1250]\n",
      "\n",
      "üîç Valeurs manquantes par colonne :\n",
      "‚úÖ Aucune valeur manquante\n",
      "\n",
      "üîç TRAITEMENT DES VALEURS ABERRANTES\n",
      "==================================================\n",
      "üìä 5 enregistrements avec valeurs aberrantes d√©tect√©s\n",
      "\n",
      "  speed_kmh:\n",
      "    ‚Ä¢ 4 outliers (1.33%)\n",
      "    ‚Ä¢ Plage des outliers: [10.00, 48.00]\n",
      "    ‚Ä¢ Plage normale: [10.00, 48.00]\n",
      "\n",
      "  traffic_density:\n",
      "    ‚Ä¢ 1 outliers (0.33%)\n",
      "    ‚Ä¢ Plage des outliers: [0.84, 0.84]\n",
      "    ‚Ä¢ Plage normale: [0.05, 0.84]\n",
      "\n",
      "‚úÖ speed_kmh: Winsorization appliqu√©e (limites: 0.01, 0.99)\n",
      "\n",
      "‚úÖ traffic_density: Winsorization appliqu√©e (limites: 0.01, 0.99)\n",
      "\n",
      "‚úÖ air_quality_index: Winsorization appliqu√©e (limites: 0.01, 0.99)\n",
      "\n",
      "üéâ Toutes les valeurs aberrantes ont √©t√© trait√©es\n",
      "\n",
      "üîç ANALYSE APR√àS TRAITEMENT DES OUTLIERS\n",
      "\n",
      "üìä ANALYSE D√âTAILL√âE DES VALEURS ABERRANTES\n",
      "============================================================\n",
      "\n",
      "üìà speed_kmh:\n",
      "  Moyenne: 28.7735\n",
      "  M√©diane: 28.5000\n",
      "  Std: 7.3249\n",
      "  Min: 12.0000\n",
      "  Max: 45.0200\n",
      "  Q1: 24.0000\n",
      "  Q3: 33.0000\n",
      "  IQR: 9.0000\n",
      "  Skewness: 0.0055\n",
      "  Kurtosis: -0.2760\n",
      "  Outliers (IQR): 0 (0.00%)\n",
      "  Plage normale: [10.5000, 46.5000]\n",
      "\n",
      "üìà traffic_density:\n",
      "  Moyenne: 0.3108\n",
      "  M√©diane: 0.2850\n",
      "  Std: 0.1671\n",
      "  Min: 0.0500\n",
      "  Max: 0.7403\n",
      "  Q1: 0.1800\n",
      "  Q3: 0.4300\n",
      "  IQR: 0.2500\n",
      "  Skewness: 0.5644\n",
      "  Kurtosis: -0.2755\n",
      "  Outliers (IQR): 0 (0.00%)\n",
      "  Plage normale: [-0.1950, 0.8050]\n",
      "\n",
      "üìà air_quality_index:\n",
      "  Moyenne: 63.9100\n",
      "  M√©diane: 63.0000\n",
      "  Std: 12.0356\n",
      "  Min: 38.9900\n",
      "  Max: 91.0100\n",
      "  Q1: 55.0000\n",
      "  Q3: 72.2500\n",
      "  IQR: 17.2500\n",
      "  Skewness: 0.2743\n",
      "  Kurtosis: -0.5516\n",
      "  Outliers (IQR): 0 (0.00%)\n",
      "  Plage normale: [29.1250, 98.1250]\n",
      "\n",
      "üìà speed_traffic_product:\n",
      "  Moyenne: 8.0841\n",
      "  M√©diane: 8.1500\n",
      "  Std: 3.3284\n",
      "  Min: 1.4000\n",
      "  Max: 16.7500\n",
      "  Q1: 5.6525\n",
      "  Q3: 10.1250\n",
      "  IQR: 4.4725\n",
      "  Skewness: 0.1512\n",
      "  Kurtosis: -0.3832\n",
      "  Outliers (IQR): 0 (0.00%)\n",
      "  Plage normale: [-1.0563, 16.8338]\n",
      "\n",
      "======================================================================\n",
      "‚úÖ PIPELINE TERMIN√â AVEC SUCC√àS\n",
      "üìã Donn√©es finales : 300 lignes, 20 colonnes\n",
      "\n",
      "üìÑ √âchantillon des donn√©es trait√©es :\n",
      "   speed_kmh  traffic_density  air_quality_index weather aqi_category\n",
      "0       42.0             0.18               45.0    Rain          Bon\n",
      "1       24.0             0.54               80.0   Sunny       Mod√©r√©\n",
      "2       25.0             0.39               66.0   Sunny       Mod√©r√©\n",
      "3       32.0             0.33               75.0   Sunny       Mod√©r√©\n",
      "4       21.0             0.43               71.0  Cloudy       Mod√©r√©\n",
      "\n",
      "üíæ Donn√©es export√©es vers : mobility_data_processed_winsorize.csv\n",
      "\n",
      "üõ†Ô∏è Pipeline ML cr√©√© avec RobustScaler: ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='median')),\n",
      "                                                 ('scaler', RobustScaler())]),\n",
      "                                 ['speed_kmh', 'traffic_density',\n",
      "                                  'air_quality_index', 'latitude', 'longitude',\n",
      "                                  'hour', 'speed_traffic_product']),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('encoder', LabelEncoder())]),\n",
      "                                 ['weather', 'aqi_category', 'speed_category',\n",
      "                                  'traffic_category', 'time_of_day'])])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. CHARGEMENT DES DONN√âES\n",
    "def load_data(file_path):\n",
    "    \"\"\"Charge les donn√©es depuis le fichier Excel\"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    print(f\"‚úÖ Donn√©es charg√©es : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "    return df\n",
    "\n",
    "# 2. D√âTECTION DES VALEURS ABERRANTES\n",
    "def detect_outliers(df, numerical_cols=None, method='iqr', threshold=1.5):\n",
    "    \"\"\"D√©tecte les valeurs aberrantes dans les colonnes num√©riques\"\"\"\n",
    "\n",
    "    if numerical_cols is None:\n",
    "        numerical_cols = ['speed_kmh', 'traffic_density', 'air_quality_index',\n",
    "                         'latitude', 'longitude']\n",
    "\n",
    "    outliers_info = {}\n",
    "    outlier_indices = set()\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        data = df[col].dropna()\n",
    "\n",
    "        if method == 'iqr':\n",
    "            # M√©thode IQR (Interquartile Range)\n",
    "            Q1 = data.quantile(0.25)\n",
    "            Q3 = data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "\n",
    "        elif method == 'zscore':\n",
    "            # M√©thode Z-score\n",
    "            z_scores = np.abs(stats.zscore(data))\n",
    "            outliers = df[z_scores > threshold]\n",
    "\n",
    "        elif method == 'percentile':\n",
    "            # M√©thode des percentiles\n",
    "            lower_bound = data.quantile(0.01)\n",
    "            upper_bound = data.quantile(0.99)\n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "\n",
    "        if len(outliers) > 0:\n",
    "            outliers_info[col] = {\n",
    "                'count': len(outliers),\n",
    "                'percentage': (len(outliers) / len(df)) * 100,\n",
    "                'indices': outliers.index.tolist(),\n",
    "                'min_value': outliers[col].min(),\n",
    "                'max_value': outliers[col].max()\n",
    "            }\n",
    "            outlier_indices.update(outliers.index)\n",
    "\n",
    "    return outliers_info, list(outlier_indices)\n",
    "\n",
    "# 3. TRAITEMENT DES VALEURS ABERRANTES\n",
    "def handle_outliers(df, numerical_cols=None, method='winsorize', winsorize_limits=(0.01, 0.01)):\n",
    "    \"\"\"Traite les valeurs aberrantes selon diff√©rentes m√©thodes\"\"\"\n",
    "\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    if numerical_cols is None:\n",
    "        numerical_cols = ['speed_kmh', 'traffic_density', 'air_quality_index']\n",
    "\n",
    "    print(\"\\nüîç TRAITEMENT DES VALEURS ABERRANTES\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # D√©tection initiale\n",
    "    outliers_info, outlier_indices = detect_outliers(df_clean, numerical_cols)\n",
    "\n",
    "    if outliers_info:\n",
    "        print(f\"üìä {len(outlier_indices)} enregistrements avec valeurs aberrantes d√©tect√©s\")\n",
    "\n",
    "        for col, info in outliers_info.items():\n",
    "            print(f\"\\n  {col}:\")\n",
    "            print(f\"    ‚Ä¢ {info['count']} outliers ({info['percentage']:.2f}%)\")\n",
    "            print(f\"    ‚Ä¢ Plage des outliers: [{info['min_value']:.2f}, {info['max_value']:.2f}]\")\n",
    "            print(f\"    ‚Ä¢ Plage normale: [{df_clean[col].min():.2f}, {df_clean[col].max():.2f}]\")\n",
    "    else:\n",
    "        print(\"‚úÖ Aucune valeur aberrante d√©tect√©e\")\n",
    "\n",
    "    # Application du traitement selon la m√©thode choisie\n",
    "    for col in numerical_cols:\n",
    "        if col not in df_clean.columns:\n",
    "            continue\n",
    "\n",
    "        if method == 'winsorize':\n",
    "            # Winsorization : remplace les extr√™mes par des percentiles\n",
    "            lower_limit = winsorize_limits[0]\n",
    "            upper_limit = 1 - winsorize_limits[1]\n",
    "\n",
    "            lower_bound = df_clean[col].quantile(lower_limit)\n",
    "            upper_bound = df_clean[col].quantile(upper_limit)\n",
    "\n",
    "            df_clean[col] = np.where(df_clean[col] < lower_bound, lower_bound, df_clean[col])\n",
    "            df_clean[col] = np.where(df_clean[col] > upper_bound, upper_bound, df_clean[col])\n",
    "\n",
    "            print(f\"\\n‚úÖ {col}: Winsorization appliqu√©e (limites: {lower_limit}, {upper_limit})\")\n",
    "\n",
    "        elif method == 'cap':\n",
    "            # Capping avec IQR\n",
    "            Q1 = df_clean[col].quantile(0.25)\n",
    "            Q3 = df_clean[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            df_clean[col] = np.where(df_clean[col] < lower_bound, lower_bound, df_clean[col])\n",
    "            df_clean[col] = np.where(df_clean[col] > upper_bound, upper_bound, df_clean[col])\n",
    "\n",
    "            print(f\"\\n‚úÖ {col}: Capping IQR appliqu√©\")\n",
    "\n",
    "        elif method == 'log':\n",
    "            # Transformation logarithmique (pour donn√©es asym√©triques)\n",
    "            if (df_clean[col] > 0).all():\n",
    "                df_clean[col] = np.log1p(df_clean[col])\n",
    "                print(f\"\\n‚úÖ {col}: Transformation logarithmique appliqu√©e\")\n",
    "            else:\n",
    "                print(f\"\\n‚ö†Ô∏è  {col}: Transformation log impossible (valeurs n√©gatives)\")\n",
    "\n",
    "        elif method == 'remove':\n",
    "            # Suppression des outliers (m√©thode agressive)\n",
    "            Q1 = df_clean[col].quantile(0.25)\n",
    "            Q3 = df_clean[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            mask = (df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)\n",
    "            df_clean = df_clean[mask]\n",
    "            print(f\"\\n‚úÖ {col}: Outliers supprim√©s\")\n",
    "\n",
    "    # V√©rification apr√®s traitement\n",
    "    outliers_info_after, _ = detect_outliers(df_clean, numerical_cols)\n",
    "    if outliers_info_after:\n",
    "        remaining_outliers = sum(info['count'] for info in outliers_info_after.values())\n",
    "        print(f\"\\n‚ö†Ô∏è  {remaining_outliers} outliers restants apr√®s traitement\")\n",
    "    else:\n",
    "        print(\"\\nüéâ Toutes les valeurs aberrantes ont √©t√© trait√©es\")\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# 4. NETTOYAGE DES DONN√âES\n",
    "def clean_data(df, outlier_method='winsorize'):\n",
    "    \"\"\"Nettoie les donn√©es avec traitement des outliers\"\"\"\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Conversion du timestamp\n",
    "    df_clean['timestamp'] = pd.to_datetime(df_clean['timestamp'])\n",
    "\n",
    "    # Extraction des caract√©ristiques temporelles\n",
    "    df_clean['hour'] = df_clean['timestamp'].dt.hour\n",
    "    df_clean['day_of_week'] = df_clean['timestamp'].dt.dayofweek\n",
    "    df_clean['month'] = df_clean['timestamp'].dt.month\n",
    "    df_clean['is_weekend'] = df_clean['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # V√©rification des valeurs manquantes\n",
    "    print(\"\\nüîç Valeurs manquantes par colonne :\")\n",
    "    missing = df_clean.isnull().sum()\n",
    "    print(missing[missing > 0] if missing.sum() > 0 else \"‚úÖ Aucune valeur manquante\")\n",
    "\n",
    "    # Imputation des valeurs manquantes\n",
    "    if missing.sum() > 0:\n",
    "        for col in df_clean.columns:\n",
    "            if df_clean[col].isnull().sum() > 0:\n",
    "                if df_clean[col].dtype in ['float64', 'int64']:\n",
    "                    df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "                else:\n",
    "                    df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "\n",
    "    # Traitement des valeurs aberrantes\n",
    "    df_clean = handle_outliers(df_clean, method=outlier_method)\n",
    "\n",
    "    # Suppression des doublons\n",
    "    initial_rows = len(df_clean)\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    removed_duplicates = initial_rows - len(df_clean)\n",
    "    if removed_duplicates > 0:\n",
    "        print(f\"\\nüìä {removed_duplicates} doublons supprim√©s\")\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# 5. TRANSFORMATION DES DONN√âES\n",
    "def transform_data(df):\n",
    "    \"\"\"Transforme les donn√©es pour l'analyse\"\"\"\n",
    "    df_transformed = df.copy()\n",
    "\n",
    "    # Cat√©gorisation des variables\n",
    "    def categorize_aqi(aqi):\n",
    "        if aqi <= 50:\n",
    "            return 'Bon'\n",
    "        elif aqi <= 100:\n",
    "            return 'Mod√©r√©'\n",
    "        elif aqi <= 150:\n",
    "            return 'Mauvais'\n",
    "        else:\n",
    "            return 'Dangereux'\n",
    "\n",
    "    df_transformed['aqi_category'] = df_transformed['air_quality_index'].apply(categorize_aqi)\n",
    "\n",
    "    def categorize_speed(speed):\n",
    "        if speed <= 20:\n",
    "            return 'Lente'\n",
    "        elif speed <= 35:\n",
    "            return 'Normale'\n",
    "        else:\n",
    "            return 'Rapide'\n",
    "\n",
    "    df_transformed['speed_category'] = df_transformed['speed_kmh'].apply(categorize_speed)\n",
    "\n",
    "    def categorize_traffic(density):\n",
    "        if density <= 0.25:\n",
    "            return 'Fluide'\n",
    "        elif density <= 0.5:\n",
    "            return 'Mod√©r√©'\n",
    "        else:\n",
    "            return 'Dense'\n",
    "\n",
    "    df_transformed['traffic_category'] = df_transformed['traffic_density'].apply(categorize_traffic)\n",
    "\n",
    "    # Encodage\n",
    "    le = LabelEncoder()\n",
    "    df_transformed['weather_encoded'] = le.fit_transform(df_transformed['weather'])\n",
    "\n",
    "    return df_transformed\n",
    "\n",
    "# 6. CR√âATION DE FEATURES\n",
    "def create_features(df):\n",
    "    \"\"\"Cr√©e de nouvelles features\"\"\"\n",
    "    df_features = df.copy()\n",
    "\n",
    "    df_features['speed_traffic_product'] = df_features['speed_kmh'] * df_features['traffic_density']\n",
    "    df_features['traffic_aqi_flag'] = ((df_features['traffic_density'] < 0.2) & \n",
    "                                      (df_features['air_quality_index'] > 70)).astype(int)\n",
    "\n",
    "    # Heures de pointe\n",
    "    def is_rush_hour(hour):\n",
    "        return 1 if (7 <= hour <= 9) or (17 <= hour <= 19) else 0\n",
    "\n",
    "    df_features['is_rush_hour'] = df_features['hour'].apply(is_rush_hour)\n",
    "\n",
    "    # Moment de la journ√©e\n",
    "    def time_of_day(hour):\n",
    "        if 5 <= hour < 12:\n",
    "            return 'Matin'\n",
    "        elif 12 <= hour < 17:\n",
    "            return 'Apr√®s-midi'\n",
    "        elif 17 <= hour < 22:\n",
    "            return 'Soir'\n",
    "        else:\n",
    "            return 'Nuit'\n",
    "\n",
    "    df_features['time_of_day'] = df_features['hour'].apply(time_of_day)\n",
    "\n",
    "\n",
    "\n",
    "    return df_features\n",
    "\n",
    "# 7. PIPELINE ML AVEC ROBUSTSCALER POUR OUTLIERS\n",
    "def create_ml_pipeline(outlier_robust=True):\n",
    "    \"\"\"Cr√©e un pipeline ML robuste aux outliers\"\"\"\n",
    "\n",
    "    numeric_features = ['speed_kmh', 'traffic_density', 'air_quality_index',\n",
    "                       'latitude', 'longitude', 'hour', 'speed_traffic_product']\n",
    "    categorical_features = ['weather', 'aqi_category', 'speed_category',\n",
    "                           'traffic_category', 'time_of_day']\n",
    "\n",
    "    # Utilisation de RobustScaler pour les outliers\n",
    "    if outlier_robust:\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),  # Median plus robuste\n",
    "            ('scaler', RobustScaler())  # Meilleur pour les outliers que StandardScaler\n",
    "        ])\n",
    "    else:\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', LabelEncoder())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "# 8. ANALYSE DES OUTLIERS D√âTAILL√âE\n",
    "def detailed_outlier_analysis(df):\n",
    "    \"\"\"Analyse d√©taill√©e des valeurs aberrantes\"\"\"\n",
    "\n",
    "    numerical_cols = ['speed_kmh', 'traffic_density', 'air_quality_index', 'speed_traffic_product']\n",
    "\n",
    "    print(\"\\nüìä ANALYSE D√âTAILL√âE DES VALEURS ABERRANTES\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        if col in df.columns:\n",
    "            data = df[col].dropna()\n",
    "\n",
    "            # Statistiques\n",
    "            stats_dict = {\n",
    "                'Moyenne': data.mean(),\n",
    "                'M√©diane': data.median(),\n",
    "                'Std': data.std(),\n",
    "                'Min': data.min(),\n",
    "                'Max': data.max(),\n",
    "                'Q1': data.quantile(0.25),\n",
    "                'Q3': data.quantile(0.75),\n",
    "                'IQR': data.quantile(0.75) - data.quantile(0.25),\n",
    "                'Skewness': data.skew(),\n",
    "                'Kurtosis': data.kurtosis()\n",
    "            }\n",
    "\n",
    "            print(f\"\\nüìà {col}:\")\n",
    "            for key, value in stats_dict.items():\n",
    "                print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "            # D√©tection IQR\n",
    "            Q1 = stats_dict['Q1']\n",
    "            Q3 = stats_dict['Q3']\n",
    "            IQR = stats_dict['IQR']\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            outlier_percentage = (len(outliers) / len(df)) * 100\n",
    "\n",
    "            print(f\"  Outliers (IQR): {len(outliers)} ({outlier_percentage:.2f}%)\")\n",
    "            print(f\"  Plage normale: [{lower_bound:.4f}, {upper_bound:.4f}]\")\n",
    "\n",
    "            # Visualisation textuelle\n",
    "            if len(outliers) > 0:\n",
    "                print(f\"  Exemples d'outliers: {outliers[col].head(5).values}\")\n",
    "\n",
    "# 9. PIPELINE COMPLET\n",
    "def run_full_pipeline(file_path, outlier_method='winsorize', outlier_robust=True):\n",
    "    \"\"\"Ex√©cute le pipeline complet avec traitement des outliers\"\"\"\n",
    "\n",
    "    print(\"üöÄ D√âMARRAGE DU PIPELINE AVEC TRAITEMENT DES OUTLIERS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üìå M√©thode de traitement des outliers: {outlier_method}\")\n",
    "    print(f\"üìå RobustScaler pour ML: {outlier_robust}\")\n",
    "\n",
    "    # √âtape 1: Chargement\n",
    "    df = load_data(file_path)\n",
    "\n",
    "    # √âtape 2: Analyse initiale des outliers\n",
    "    print(\"\\nüîç ANALYSE INITIALE DES OUTLIERS\")\n",
    "    detailed_outlier_analysis(df)\n",
    "\n",
    "    # √âtape 3: Nettoyage avec traitement des outliers\n",
    "    df = clean_data(df, outlier_method=outlier_method)\n",
    "\n",
    "    # √âtape 4: Transformation\n",
    "    df = transform_data(df)\n",
    "\n",
    "    # √âtape 5: Cr√©ation de features\n",
    "    df = create_features(df)\n",
    "\n",
    "    # √âtape 6: Analyse apr√®s traitement\n",
    "    print(\"\\nüîç ANALYSE APR√àS TRAITEMENT DES OUTLIERS\")\n",
    "    detailed_outlier_analysis(df)\n",
    "\n",
    "    # √âtape 7: Pipeline ML robuste\n",
    "    preprocessor = create_ml_pipeline(outlier_robust=outlier_robust)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ PIPELINE TERMIN√â AVEC SUCC√àS\")\n",
    "    print(f\"üìã Donn√©es finales : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "\n",
    "    return df, preprocessor\n",
    "\n",
    "# 10. EXPORT DES R√âSULTATS\n",
    "def export_results(df, output_path='processed_mobility_data_with_outliers.csv'):\n",
    "    \"\"\"Exporte les donn√©es trait√©es\"\"\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nüíæ Donn√©es export√©es vers : {output_path}\")\n",
    "\n",
    "# 11. EX√âCUTION AVEC OPTIONS\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_FILE = \"C:/Users/PC/Desktop/Bootcamp_FN/mobility_urban_pollution_300.xlsx\"\n",
    "\n",
    "    # Options de traitement des outliers\n",
    "    METHODS = {\n",
    "        'winsorize': 'Winsorization (remplacement par percentiles)',\n",
    "        'cap': 'Capping IQR (troncature des extr√™mes)',\n",
    "        'log': 'Transformation logarithmique',\n",
    "        'remove': 'Suppression des outliers'\n",
    "    }\n",
    "\n",
    "    print(\"üéØ OPTIONS DE TRAITEMENT DES OUTLIERS\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, value in METHODS.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    # Choix de la m√©thode (vous pouvez le rendre interactif)\n",
    "    chosen_method = 'winsorize'  # Par d√©faut\n",
    "    # Pour rendre interactif : chosen_method = input(\"\\nChoisissez une m√©thode: \")\n",
    "\n",
    "    try:\n",
    "        # Ex√©cution avec la m√©thode choisie\n",
    "        processed_data, ml_pipeline = run_full_pipeline(\n",
    "            INPUT_FILE,\n",
    "            outlier_method=chosen_method,\n",
    "            outlier_robust=True\n",
    "        )\n",
    "\n",
    "        # Affichage d'√©chantillon\n",
    "        print(\"\\nüìÑ √âchantillon des donn√©es trait√©es :\")\n",
    "        print(processed_data[['speed_kmh', 'traffic_density', 'air_quality_index',\n",
    "                              'weather', 'aqi_category']].head())\n",
    "\n",
    "        # Export\n",
    "        export_results(processed_data, f\"mobility_data_processed_{chosen_method}.csv\")\n",
    "\n",
    "        print(f\"\\nüõ†Ô∏è Pipeline ML cr√©√© avec RobustScaler: {ml_pipeline}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erreur : {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8d57f8b-0ff8-4324-ac10-04a7a75d6aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>speed_kmh</th>\n",
       "      <th>traffic_density</th>\n",
       "      <th>air_quality_index</th>\n",
       "      <th>weather</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>aqi_category</th>\n",
       "      <th>speed_category</th>\n",
       "      <th>traffic_category</th>\n",
       "      <th>weather_encoded</th>\n",
       "      <th>speed_traffic_product</th>\n",
       "      <th>traffic_aqi_flag</th>\n",
       "      <th>is_rush_hour</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R004</td>\n",
       "      <td>2025-08-01 13:17:05</td>\n",
       "      <td>14.69869</td>\n",
       "      <td>-17.35986</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bon</td>\n",
       "      <td>Rapide</td>\n",
       "      <td>Fluide</td>\n",
       "      <td>2</td>\n",
       "      <td>7.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apr√®s-midi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R008</td>\n",
       "      <td>2025-08-03 23:00:53</td>\n",
       "      <td>14.67364</td>\n",
       "      <td>-17.51332</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>Normale</td>\n",
       "      <td>Dense</td>\n",
       "      <td>3</td>\n",
       "      <td>12.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R004</td>\n",
       "      <td>2025-08-07 20:50:58</td>\n",
       "      <td>14.68798</td>\n",
       "      <td>-17.47673</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>Normale</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>3</td>\n",
       "      <td>9.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Soir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R014</td>\n",
       "      <td>2025-08-01 15:15:26</td>\n",
       "      <td>14.65846</td>\n",
       "      <td>-17.36022</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>Normale</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>3</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apr√®s-midi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R007</td>\n",
       "      <td>2025-08-04 01:46:02</td>\n",
       "      <td>14.66586</td>\n",
       "      <td>-17.45096</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>Normale</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nuit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  route_id           timestamp  latitude  longitude  speed_kmh  \\\n",
       "0     R004 2025-08-01 13:17:05  14.69869  -17.35986       42.0   \n",
       "1     R008 2025-08-03 23:00:53  14.67364  -17.51332       24.0   \n",
       "2     R004 2025-08-07 20:50:58  14.68798  -17.47673       25.0   \n",
       "3     R014 2025-08-01 15:15:26  14.65846  -17.36022       32.0   \n",
       "4     R007 2025-08-04 01:46:02  14.66586  -17.45096       21.0   \n",
       "\n",
       "   traffic_density  air_quality_index weather  hour  day_of_week  month  \\\n",
       "0             0.18               45.0    Rain    13            4      8   \n",
       "1             0.54               80.0   Sunny    23            6      8   \n",
       "2             0.39               66.0   Sunny    20            3      8   \n",
       "3             0.33               75.0   Sunny    15            4      8   \n",
       "4             0.43               71.0  Cloudy     1            0      8   \n",
       "\n",
       "   is_weekend aqi_category speed_category traffic_category  weather_encoded  \\\n",
       "0           0          Bon         Rapide           Fluide                2   \n",
       "1           1       Mod√©r√©        Normale            Dense                3   \n",
       "2           0       Mod√©r√©        Normale           Mod√©r√©                3   \n",
       "3           0       Mod√©r√©        Normale           Mod√©r√©                3   \n",
       "4           0       Mod√©r√©        Normale           Mod√©r√©                0   \n",
       "\n",
       "   speed_traffic_product  traffic_aqi_flag  is_rush_hour time_of_day  \n",
       "0                   7.56                 0             0  Apr√®s-midi  \n",
       "1                  12.96                 0             0        Nuit  \n",
       "2                   9.75                 0             0        Soir  \n",
       "3                  10.56                 0             0  Apr√®s-midi  \n",
       "4                   9.03                 0             0        Nuit  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a60c51f-882d-4c3c-babd-bb2716c6e580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pymysql\n",
      "  Downloading pymysql-1.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading pymysql-1.1.2-py3-none-any.whl (45 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c216ad2c-8ba5-4ef8-8c68-44e96c8f3abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connect√© √† MySQL avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# Connexion √† MySQL local\n",
    "def connect_to_mysql():\n",
    "    \"\"\"√âtablit la connexion √† MySQL\"\"\"\n",
    "    try:\n",
    "        engine = create_engine(\"mysql+pymysql://root@localhost/mobility_db\")\n",
    "        connection = engine.connect()\n",
    "        print(\"‚úÖ Connect√© √† MySQL avec succ√®s\")\n",
    "        return engine, connection\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur de connexion: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Tester la connexion\n",
    "engine, conn = connect_to_mysql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1458c9d-3330-4252-915a-78c4d4bc1b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Colonnes disponibles dans vos donn√©es:\n",
      "['route_id', 'timestamp', 'latitude', 'longitude', 'speed_kmh', 'traffic_density', 'air_quality_index', 'weather', 'hour', 'day_of_week', 'month', 'is_weekend', 'aqi_category', 'speed_category', 'traffic_category', 'weather_encoded', 'speed_traffic_product', 'traffic_aqi_flag', 'is_rush_hour', 'time_of_day']\n",
      "‚úÖ 300 lignes ins√©r√©es\n",
      "üìä Total dans la table: 300 lignes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_to_existing_table(df, table_name='mobility_processed'):\n",
    "    \"\"\"Ins√®re dans la table existante avec mapping des colonnes\"\"\"\n",
    "    \n",
    "    # V√©rifier les colonnes\n",
    "    print(\"üìã Colonnes disponibles dans vos donn√©es:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    # Mapping entre vos colonnes et la table\n",
    "    column_mapping = {\n",
    "        'route_id': 'route_id',\n",
    "        'timestamp': 'timestamp',\n",
    "        'latitude': 'latitude',\n",
    "        'longitude': 'longitude',\n",
    "        'speed_kmh': 'speed_kmh',\n",
    "        'traffic_density': 'traffic_density',\n",
    "        'air_quality_index': 'air_quality_index',\n",
    "        'weather': 'weather',\n",
    "        'hour': 'hour',\n",
    "        'day_of_week': 'day_of_week',\n",
    "        'month': 'month',\n",
    "        'is_weekend': 'is_weekend',\n",
    "        'aqi_category': 'aqi_category',\n",
    "        'speed_category': 'speed_category',\n",
    "        'traffic_category': 'traffic_category',\n",
    "        'weather_encoded': 'weather_encoded',\n",
    "        'speed_traffic_product': 'speed_traffic_product',\n",
    "        'traffic_aqi_flag': 'traffic_aqi_flag',\n",
    "        'is_rush_hour': 'is_rush_hour',\n",
    "        'time_of_day': 'time_of_day'\n",
    "        # 'created_at' sera auto-g√©n√©r√©\n",
    "    }\n",
    "    \n",
    "    # S√©lectionner et renommer les colonnes\n",
    "    df_to_insert = df[list(column_mapping.keys())].rename(columns=column_mapping)\n",
    "    \n",
    "    # Connexion MySQL\n",
    "    engine = create_engine(\"mysql+pymysql://root@localhost/mobility_db\")\n",
    "    \n",
    "    # Ins√©rer avec append (ne pas remplacer la table)\n",
    "    df_to_insert.to_sql(table_name, \n",
    "                       engine, \n",
    "                       if_exists='append',  # ‚Üê CRUCIAL: 'append' pas 'replace'\n",
    "                       index=False)\n",
    "    \n",
    "    # V√©rifier\n",
    "    count = pd.read_sql(f\"SELECT COUNT(*) as count FROM {table_name}\", engine)\n",
    "    print(f\"‚úÖ {len(df_to_insert)} lignes ins√©r√©es\")\n",
    "    print(f\"üìä Total dans la table: {count['count'][0]} lignes\")\n",
    "    \n",
    "    engine.dispose()\n",
    "    return True\n",
    "\n",
    "# Utilisation\n",
    "save_to_existing_table(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c68ee99-05a3-45a9-92d1-619eee2f1b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>speed_kmh</th>\n",
       "      <th>traffic_density</th>\n",
       "      <th>air_quality_index</th>\n",
       "      <th>weather</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>aqi_category</th>\n",
       "      <th>speed_category</th>\n",
       "      <th>traffic_category</th>\n",
       "      <th>weather_encoded</th>\n",
       "      <th>speed_traffic_product</th>\n",
       "      <th>traffic_aqi_flag</th>\n",
       "      <th>is_rush_hour</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>R004</td>\n",
       "      <td>2025-08-01 13:17:05</td>\n",
       "      <td>14.69869</td>\n",
       "      <td>-17.35986</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>45</td>\n",
       "      <td>Rain</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bon</td>\n",
       "      <td>Rapide</td>\n",
       "      <td>Fluide</td>\n",
       "      <td>2</td>\n",
       "      <td>7.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apr√®s-midi</td>\n",
       "      <td>2026-01-16 21:30:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>R008</td>\n",
       "      <td>2025-08-03 23:00:53</td>\n",
       "      <td>14.67364</td>\n",
       "      <td>-17.51332</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>80</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>Normale</td>\n",
       "      <td>Dense</td>\n",
       "      <td>3</td>\n",
       "      <td>12.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nuit</td>\n",
       "      <td>2026-01-16 21:30:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>R004</td>\n",
       "      <td>2025-08-07 20:50:58</td>\n",
       "      <td>14.68798</td>\n",
       "      <td>-17.47673</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>66</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>Normale</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>3</td>\n",
       "      <td>9.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Soir</td>\n",
       "      <td>2026-01-16 21:30:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>R014</td>\n",
       "      <td>2025-08-01 15:15:26</td>\n",
       "      <td>14.65846</td>\n",
       "      <td>-17.36022</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>75</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>Normale</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>3</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apr√®s-midi</td>\n",
       "      <td>2026-01-16 21:30:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>R007</td>\n",
       "      <td>2025-08-04 01:46:02</td>\n",
       "      <td>14.66586</td>\n",
       "      <td>-17.45096</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>71</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>Normale</td>\n",
       "      <td>Mod√©r√©</td>\n",
       "      <td>0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nuit</td>\n",
       "      <td>2026-01-16 21:30:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id route_id           timestamp  latitude  longitude  speed_kmh  \\\n",
       "0   1     R004 2025-08-01 13:17:05  14.69869  -17.35986       42.0   \n",
       "1   2     R008 2025-08-03 23:00:53  14.67364  -17.51332       24.0   \n",
       "2   3     R004 2025-08-07 20:50:58  14.68798  -17.47673       25.0   \n",
       "3   4     R014 2025-08-01 15:15:26  14.65846  -17.36022       32.0   \n",
       "4   5     R007 2025-08-04 01:46:02  14.66586  -17.45096       21.0   \n",
       "\n",
       "   traffic_density  air_quality_index weather  hour  ...  is_weekend  \\\n",
       "0             0.18                 45    Rain    13  ...           0   \n",
       "1             0.54                 80   Sunny    23  ...           1   \n",
       "2             0.39                 66   Sunny    20  ...           0   \n",
       "3             0.33                 75   Sunny    15  ...           0   \n",
       "4             0.43                 71  Cloudy     1  ...           0   \n",
       "\n",
       "   aqi_category  speed_category traffic_category weather_encoded  \\\n",
       "0           Bon          Rapide           Fluide               2   \n",
       "1        Mod√©r√©         Normale            Dense               3   \n",
       "2        Mod√©r√©         Normale           Mod√©r√©               3   \n",
       "3        Mod√©r√©         Normale           Mod√©r√©               3   \n",
       "4        Mod√©r√©         Normale           Mod√©r√©               0   \n",
       "\n",
       "  speed_traffic_product  traffic_aqi_flag  is_rush_hour  time_of_day  \\\n",
       "0                  7.56                 0             0   Apr√®s-midi   \n",
       "1                 12.96                 0             0         Nuit   \n",
       "2                  9.75                 0             0         Soir   \n",
       "3                 10.56                 0             0   Apr√®s-midi   \n",
       "4                  9.03                 0             0         Nuit   \n",
       "\n",
       "           created_at  \n",
       "0 2026-01-16 21:30:06  \n",
       "1 2026-01-16 21:30:06  \n",
       "2 2026-01-16 21:30:06  \n",
       "3 2026-01-16 21:30:06  \n",
       "4 2026-01-16 21:30:06  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT * FROM mobility_processed LIMIT 10\"\n",
    "df_result = pd.read_sql(query, engine)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f6e94-212f-4f51-a0b3-2586713e8811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
