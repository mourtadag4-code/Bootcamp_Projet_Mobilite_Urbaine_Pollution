# ğŸš—ğŸ“Š Analyse des DonnÃ©es de MobilitÃ© Urbaine et de la Pollution

## ğŸ“‹ Contexte
Projet rÃ©alisÃ© dans le cadre du Bootcamp FORCE-N (Data Analysis & Data Engineering) sur l'analyse des donnÃ©es de mobilitÃ© urbaine au SÃ©nÃ©gal.

## ğŸ¯ Objectifs
- Pipeline de traitement des donnÃ©es de mobilitÃ© et pollution
- Identification des zones et crÃ©neaux horaires critiques
- Dashboard interactif de visualisation
- Recommandations pour rÃ©duire congestion et pollution

## Ã‰quipe â€“ Groupe 2
Mouhamadoul Mourtadha GUEYE
Babacar WADE
Mame MarÃ©me DIA
Absa SYLLA
Lamine NDIAYE
Cheikh Ahmed Tidiane Baidy GUEYE


## ğŸ—ï¸ Architecture du Projet
Bootcamp_Projet_Mobilite_Urbaine_Pollution/
â”œâ”€â”€ data/ # DonnÃ©es
â”‚ â”œâ”€â”€ mobility_urban_pollution_300.xlsx # DonnÃ©es brutes (non versionnÃ©es)
â”‚ â””â”€â”€ mobility_data_processed_winsorize.csv # DonnÃ©es nettoyÃ©es
â”œâ”€â”€ notebooks/ # Notebooks d'analyse exploratoire
â”‚ â”œâ”€â”€ analysis.ipynb # Exploration
| â”œâ”€â”€ btcamp.ipynb # Exploration
â”œâ”€â”€ src/ # Code source principal
â”‚ â”‚â”€â”€ pipeline.py # Pipeline de traitement principal
â”‚ â”œâ”€â”€ db_connector.py # Connexion MySQL
â”‚ â”‚â”€â”€ app.py # dashboard streamlit
â”œâ”€â”€ docs/ # Documentation
â”œâ”€â”€ .gitignore # Fichiers ignorÃ©s par Git
â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â”œâ”€â”€ main.py # Point d'entrÃ©e du pipeline
â””â”€â”€ README.md # Ce fichier

## Outils UtilisÃ©s

CatÃ©gorie	                    Outils
Analyse & Traitement	        Python, Pandas, NumPy, Scikit-learn
Visualisation               	Matplotlib, Seaborn, Power BI
Pipeline & Base de donnÃ©es  	MySQL, SQLAlchemy, PyMySQL
Gestion de projet           	Git, PowerPoint, Jupyter Notebook

## âš™ï¸ Installation

### PrÃ©requis
- Python/Pandas
- MySQL Server (optionnel pour l'analyse locale)
- Git
- Power BI

### 1. Cloner le dÃ©pÃ´t
git clone https://github.com/mourtadag4-code/Bootcamp_Projet_Mobilite_Urbaine_Pollution.git
cd Bootcamp_Projet_Mobilite_Urbaine_Pollution

### 2. Installer les dÃ©pendances
pip install -r requirements.txt

## Utilisation
### ExÃ©cuter le pipeline complet
python main.py

### ExÃ©cuter Ã©tape par Ã©tape
### 1. Dans un notebook Jupyter ou script Python
from src.data_processing.pipeline import run_full_pipeline
from src.database.connector import save_to_mysql

### 2. Traiter les donnÃ©es
df_processed = run_full_pipeline('data/raw/mobility_data.xlsx')

### 3. Sauvegarder dans MySQL (optionnel)
save_to_mysql(df_processed, table_name='mobility_processed')

### 4. Analyser les donnÃ©es
print(df_processed.describe())

### AccÃ©der aux donnÃ©es pour analyse
import pandas as pd
df = pd.read_csv('data/mobility_data_processed_winsorize.csv')

## Ã‰tapes du Projet
### Chargement et Exploration des DonnÃ©es
DonnÃ©es initiales : 300 lignes, 8 colonnes (route_id, timestamp, latitude, longitude, speed_kmh, traffic_density, air_quality_index, weather).

Aucune valeur manquante dÃ©tectÃ©e.

### Nettoyage et Transformation
Conversion du timestamp et extraction de features temporelles (hour, day_of_week, month, is_weekend).
Traitement des outliers via plusieurs mÃ©thodes (Winsorization, Capping IQR, Log, Suppression).
CatÃ©gorisation des variables :
    aqi_category (Bon, ModÃ©rÃ©, Mauvais, Dangereux)
    speed_category (Lente, Normale, Rapide)
    traffic_category (Fluide, ModÃ©rÃ©, Dense)
CrÃ©ation de nouvelles variables : speed_traffic_product, traffic_aqi_flag, is_rush_hour

###  Pipeline de DonnÃ©es
IntÃ©gration dâ€™un pipeline de prÃ©traitement robuste avec RobustScaler pour gÃ©rer les valeurs aberrantes.
Sauvegarde des donnÃ©es traitÃ©es en CSV et injection dans une base MySQL (mobility_db.mobility_processed).

### Analyse Exploratoire
Analyse univariÃ©e : statistiques descriptives, distribution des variables clÃ©s.
Analyse bivariÃ©e : relations entre vitesse, densitÃ©, qualitÃ© de lâ€™air et conditions mÃ©tÃ©o.
Visualisations : histograms, boxplots, scatter plots, heatmaps.

###  Tableau de Bord Interactif
DÃ©veloppement dâ€™un dashboard sous Power BI pour :
    Visualiser les zones critiques (congestion, pollution).
    Analyser les tendances temporelles (heures de pointe, weekends).
    Croiser les donnÃ©es mÃ©tÃ©o avec les indicateurs de mobilitÃ©.

## RÃ©sultats ClÃ©s
Vitesse Moyenne
    Moyenne : 28.8 km/h
    MÃ©diane : 28.5 km/h
InterprÃ©tation : Circulation urbaine typique, avec des vitesses faibles suggÃ©rant une congestion frÃ©quente.

QualitÃ© de lâ€™Air (AQI)
    Moyenne : 63.9 (niveau modÃ©rÃ©)
    Pics jusquâ€™Ã  97 (mauvaise qualitÃ©)
Lien probable avec la densitÃ© du trafic.

DensitÃ© du Trafic
    Moyenne : 0.31
    Max : 0.84 (forte congestion)
Distribution : majoritÃ© des situations modÃ©rÃ©es, avec des pics localisÃ©s.

##  Pipeline DÃ©taillÃ©
# Exemple de pipeline principal
processed_data, ml_pipeline = run_full_pipeline(
    file_path="data/raw/mobility_urban_pollution_300.xlsx",
    outlier_method="winsorize",
    outlier_robust=True
)

Sorties :
    DonnÃ©es nettoyÃ©es et enrichies (20 colonnes)
    Pipeline ML prÃªt pour la modÃ©lisation (ColumnTransformer avec RobustScaler)
    Export CSV et insertion MySQL automatique

## Recommandations OpÃ©rationnelles
- Fluidifier le trafic aux heures de pointe par une rÃ©gulation dynamique.
- Promouvoir les transports en commun et les mobilitÃ©s douces.
- Surveiller la qualitÃ© de lâ€™air dans les zones Ã  fort trafic.
- Ã‰tudier les corrÃ©lations trafic-pollution pour des politiques ciblÃ©es.
- GÃ©nÃ©raliser lâ€™approche data-driven Ã  dâ€™autres villes sÃ©nÃ©galaises.

## Livrables
Pipeline de donnÃ©es fonctionnel (Python/SQL, Jupyter, Airflow/dbt)
Dashboard interactif (Streamlit)
PrÃ©sentation synthÃ¨se (5â€“7 slides)
Code source et documentation (GitHub)